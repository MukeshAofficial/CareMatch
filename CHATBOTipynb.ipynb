{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW4_saMlkOgV"
      },
      "outputs": [],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "66cmXVq-kPaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "openai.api_key = 'You api key'\n",
        "\n",
        "st.title(\"MEDICAL BOT \")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"Ask me\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "        messages_for_openai = []\n",
        "        for m in st.session_state.messages:\n",
        "            messages_for_openai.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
        "        for response in openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages_for_openai,\n",
        "            stream=True,\n",
        "        ):\n",
        "            full_response += response.choices[0].delta.get(\"content\", \"\")\n",
        "            message_placeholder.markdown(full_response + \"â–Œ\")\n",
        "        message_placeholder.markdown(full_response)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_F5CbSOkT2v",
        "outputId": "b0c19480-9c10-4176-b61f-34d13b67c96f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "LLgCLpTRkYUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "FNfMRYcskb9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}